{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f859211-dac8-4fbb-8013-0307011b6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3864cdcf-2dc8-4f9c-bf4f-72ac94238cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from albumentations) (1.13.0)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from albumentations) (0.23.2)\n",
      "Requirement already satisfied: PyYAML in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from albumentations) (4.11.0)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from albumentations) (1.4.2)\n",
      "Requirement already satisfied: pydantic>=2.6.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from albumentations) (2.7.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from albumentations) (4.9.0.80)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic>=2.6.4->albumentations) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic>=2.6.4->albumentations) (2.18.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-image>=0.21.0->albumentations) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.33 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-image>=0.21.0->albumentations) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-image>=0.21.0->albumentations) (2024.4.18)\n",
      "Requirement already satisfied: packaging>=21 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn>=1.3.2->albumentations) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn>=1.3.2->albumentations) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c4dd18-3bb3-41f3-a312-b657c124ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cbe54b5-8925-48b1-aa9f-78141a9cccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path = [\n",
    "    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n",
    "] + sys.path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c83ef1-6f58-452d-9406-2ceb512e7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "# from warmup_scheduler import GradualWarmupScheduler\n",
    "from efficientnet_pytorch import model as enet\n",
    "import albumentations\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e42b37-1ba5-4823-abc7-ebe627e5a52d",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee7e582-6b0e-45da-9100-ffc05d47a043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9464\n",
      "1052\n",
      "/teamspace/studios/this_studio/Prostate_Cancer_Grade_Assessment/dataset/train-tiled-prostate-36x256x256\n",
      "/teamspace/studios/this_studio/Prostate_Cancer_Grade_Assessment/dataset/test-tiled-prostate-36x256x256\n"
     ]
    }
   ],
   "source": [
    "DATASET_FOLDER_PATH: str = os.path.join(os.path.abspath('./Prostate_Cancer_Grade_Assessment'), 'dataset')\n",
    "TRAINING_DATA_FOLDER: str = 'train-tiled-prostate-36x256x256'\n",
    "TESTING_DATA_FOLDER: str = 'test-tiled-prostate-36x256x256'\n",
    "TRAIN_DATA_CSV_PATH: str = os.path.join(DATASET_FOLDER_PATH, TRAINING_DATA_FOLDER, 'train.csv')\n",
    "TEST_DATA_CSV_PATH: str = os.path.join(DATASET_FOLDER_PATH, TESTING_DATA_FOLDER, 'test.csv')\n",
    "\n",
    "# data_dir = '../input/prostate-cancer-grade-assessment' # Prostate_Cancer_Grade_Assessment/dataset/train-tiled-prostate-36x256x256\n",
    "df_train = pd.read_csv(TRAIN_DATA_CSV_PATH)\n",
    "df_train = df_train[df_train.is_present == 1].reset_index(drop=True).copy()\n",
    "print(len(df_train))\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATA_CSV_PATH)\n",
    "df_test = df_test[df_test.is_present == 1].reset_index(drop=True).copy()\n",
    "print(len(df_test))\n",
    "\n",
    "TRAINING_DATA_FOLDER_PATH = os.path.join(DATASET_FOLDER_PATH, TRAINING_DATA_FOLDER)\n",
    "TESTING_DATA_FOLDER_PATH = os.path.join(DATASET_FOLDER_PATH, TESTING_DATA_FOLDER)\n",
    "\n",
    "kernel_type = 'how_to_train_effnet_b0_to_get_LB_0.86'\n",
    "\n",
    "enet_type = 'efficientnet-b0'\n",
    "fold = 0\n",
    "tile_size = 256\n",
    "image_size = 256\n",
    "n_tiles = 36\n",
    "batch_size = 2\n",
    "num_workers = 8\n",
    "out_dim = 5\n",
    "init_lr = 3e-4\n",
    "warmup_factor = 10\n",
    "\n",
    "warmup_epo = 1\n",
    "n_epochs = 10 if DEBUG else 30\n",
    "df_train = df_train.sample(100).reset_index(drop=True) if DEBUG else df_train\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print(TRAINING_DATA_FOLDER_PATH)\n",
    "print(TESTING_DATA_FOLDER_PATH)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "device1 = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "nprocs = torch.cuda.device_count() if device1 == \"cuda\" else 1\n",
    "\n",
    "master_addr = os.environ.get(\"MASTER_ADDR\", \"127.0.0.1\")\n",
    "master_port = os.environ.get(\"MASTER_PORT\", \"6006\")\n",
    "global_rank = int(os.environ.get(\"RANK\", -1))\n",
    "local_rank = int(os.environ.get(\"LOCAL_RANK\", -1))\n",
    "world_size = int(os.environ.get(\"WORLD_SIZE\", nprocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17a1bc95-079a-40b4-a5fa-700b553ea98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/Prostate_Cancer_Grade_Assessment/dataset'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_FOLDER_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e4da9-38f5-4c19-b0fd-9edad4c43c76",
   "metadata": {},
   "source": [
    "# Create Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a51d674-5038-465a-8d52-d9d365c33f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>is_present</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002a4db09dad406c85505a00fb6f6144</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003046e27c8ead3e3db155780dc5498e</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score  \\\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0   \n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0   \n",
       "2  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4   \n",
       "3  002a4db09dad406c85505a00fb6f6144    karolinska           0           0+0   \n",
       "4  003046e27c8ead3e3db155780dc5498e    karolinska           1           3+3   \n",
       "\n",
       "   is_present  fold  \n",
       "0           1     4  \n",
       "1           1     4  \n",
       "2           1     0  \n",
       "3           1     1  \n",
       "4           1     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "df_train['fold'] = -1\n",
    "for i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['isup_grade'])):\n",
    "    df_train.loc[valid_idx, 'fold'] = i\n",
    "    \n",
    "print(len(df_train))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10279f00-4f94-4574-8187-16f8b300aeb3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65b7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = {\n",
    "    'efficientnet-b0': '/teamspace/studios/this_studio/Prostate_Cancer_Grade_Assessment/pre_trained_models/efficientnet-b0-08094119.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7854c9-0489-4417-b470-aaad9a415f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class enetv2(nn.Module):\n",
    "    def __init__(self, backbone, out_dim):\n",
    "        super(enetv2, self).__init__()\n",
    "        # self.enet = enet.EfficientNet.from_name(backbone)\n",
    "        # self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n",
    "        self.enet = enet.EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n",
    "        self.enet._fc = nn.Identity()\n",
    "\n",
    "    def extract(self, x):\n",
    "        return self.enet(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extract(x)\n",
    "        x = self.myfc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e70adb6-3d17-4dd0-af4b-9d7b77ba6a42",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f77f24c-8494-4e4f-872a-7359129389b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tiles(img, mode=0):\n",
    "        result = []\n",
    "        h, w, c = img.shape\n",
    "        pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n",
    "        pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n",
    "\n",
    "        img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n",
    "        img3 = img2.reshape(\n",
    "            img2.shape[0] // tile_size,\n",
    "            tile_size,\n",
    "            img2.shape[1] // tile_size,\n",
    "            tile_size,\n",
    "            3\n",
    "        )\n",
    "\n",
    "        img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n",
    "        n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n",
    "        if len(img3) < n_tiles:\n",
    "            img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n",
    "        idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n",
    "        img3 = img3[idxs]\n",
    "        for i in range(len(img3)):\n",
    "            result.append({'img':img3[i], 'idx':i})\n",
    "        return result, n_tiles_with_info >= n_tiles\n",
    "    \n",
    "def create_tiles_object_from_images(folder_path, list_tile_img_files, list_tile_mask_files=[], include_mask=False):\n",
    "        tiles = []\n",
    "\n",
    "        if include_mask:\n",
    "            for i, (tile_img_file, tile_mask_file) in enumerate(zip(list_tile_img_files, list_tile_mask_files)):\n",
    "                tile_img = np.asarray(Image.open(os.path.join(folder_path, 'images', tile_img_file)))\n",
    "                tile_mask = np.asarray(Image.open(os.path.join(folder_path, 'masks', tile_mask_file)))\n",
    "                tiles.append({'img': tile_img, 'mask': tile_mask, 'idx': i})\n",
    "        else:\n",
    "            for i, tile_img_file in enumerate(list_tile_img_files):\n",
    "                tile_img = np.asarray(Image.open(os.path.join(folder_path, 'images', tile_img_file)))\n",
    "                tiles.append({'img': tile_img, 'idx': i})\n",
    "        \n",
    "        return tiles\n",
    "\n",
    "class PANDADataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 folder_path,\n",
    "                 df,\n",
    "                 image_size,\n",
    "                 n_tiles=n_tiles,\n",
    "                 tile_mode=0,\n",
    "                 rand=False,\n",
    "                 transform=None,\n",
    "                ):\n",
    "        self.folder_path = folder_path\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_size = image_size\n",
    "        self.n_tiles = n_tiles\n",
    "        self.tile_mode = tile_mode\n",
    "        self.rand = rand\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        img_id = row.image_id\n",
    "        \n",
    "        # tiff_file = os.path.join(IMAGES_FOLDER, f'{img_id}.tiff')\n",
    "        # image = skimage.io.MultiImage(tiff_file)[1]\n",
    "        # tiles, _ = get_tiles(image, self.tile_mode)\n",
    "        list_idx = list(range(0, n_tiles))\n",
    "        list_tile_img_files = [f'{img_id}_{str(i)}.png' for i in list_idx]\n",
    "        tiles = create_tiles_object_from_images(self.folder_path, list_tile_img_files, include_mask=False)\n",
    "\n",
    "        if self.rand:\n",
    "            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n",
    "        else:\n",
    "            idxes = list(range(self.n_tiles))\n",
    "\n",
    "        n_row_tiles = int(np.sqrt(self.n_tiles))\n",
    "        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n",
    "        for h in range(n_row_tiles):\n",
    "            for w in range(n_row_tiles):\n",
    "                i = h * n_row_tiles + w\n",
    "    \n",
    "                if len(tiles) > idxes[i]:\n",
    "                    this_img = tiles[idxes[i]]['img']\n",
    "                else:\n",
    "                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n",
    "                this_img = 255 - this_img\n",
    "                if self.transform is not None:\n",
    "                    this_img = self.transform(image=this_img)['image']\n",
    "                h1 = h * image_size\n",
    "                w1 = w * image_size\n",
    "                images[h1:h1+image_size, w1:w1+image_size] = this_img\n",
    "\n",
    "        if self.transform is not None:\n",
    "            images = self.transform(image=images)['image']\n",
    "        images = images.astype(np.float32)\n",
    "        images /= 255\n",
    "        images = images.transpose(2, 0, 1)\n",
    "\n",
    "        label = np.zeros(5).astype(np.float32)\n",
    "        label[:row.isup_grade] = 1.\n",
    "        return torch.tensor(images), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db26c827-9ab6-439b-8333-83fa767cd88c",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "547b7b8b-4cf1-4617-be37-3a8e24611e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = albumentations.Compose([\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "])\n",
    "transforms_val = albumentations.Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "225c6f85-2852-432f-85f6-7a94b58dc3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_show = PANDADataset(TESTING_DATA_FOLDER_PATH, df_test, image_size, n_tiles, 0, transform=None)\n",
    "# from pylab import rcParams\n",
    "# rcParams['figure.figsize'] = 20,10\n",
    "# for i in range(2):\n",
    "#     f, axarr = plt.subplots(1,5)\n",
    "#     for p in range(5):\n",
    "#         idx = np.random.randint(0, len(dataset_show))\n",
    "#         img, label = dataset_show[idx]\n",
    "#         axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n",
    "#         axarr[p].set_title(str(sum(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9b37a-0a0c-44ba-8d8f-9d059f5c71bf",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "109d2a1a-84a5-4de0-beb4-b16156370dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162b1b1",
   "metadata": {},
   "source": [
    "# Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "070f646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class GradualWarmupScheduler(_LRScheduler):\n",
    "    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n",
    "    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n",
    "\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n",
    "        total_epoch: target learning rate is reached at total_epoch, gradually\n",
    "        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        self.multiplier = multiplier\n",
    "        if self.multiplier < 1.:\n",
    "            raise ValueError('multiplier should be greater thant or equal to 1.')\n",
    "        self.total_epoch = total_epoch\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished = False\n",
    "        super(GradualWarmupScheduler, self).__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n",
    "        if self.last_epoch <= self.total_epoch:\n",
    "            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n",
    "                param_group['lr'] = lr\n",
    "        else:\n",
    "            if epoch is None:\n",
    "                self.after_scheduler.step(metrics, None)\n",
    "            else:\n",
    "                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n",
    "\n",
    "    def step(self, epoch=None, metrics=None):\n",
    "        if type(self.after_scheduler) != ReduceLROnPlateau:\n",
    "            if self.finished and self.after_scheduler:\n",
    "                if epoch is None:\n",
    "                    self.after_scheduler.step(None)\n",
    "                else:\n",
    "                    self.after_scheduler.step(epoch - self.total_epoch)\n",
    "                self._last_lr = self.after_scheduler.get_lr()\n",
    "            else:\n",
    "                return super(GradualWarmupScheduler, self).step(epoch)\n",
    "        else:\n",
    "            self.step_ReduceLROnPlateau(metrics, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f7d05-a6da-4254-8c58-aafc460cf788",
   "metadata": {},
   "source": [
    "# Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c175e5a8-49f7-490c-8cd1-5a4edc82c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loader, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader)\n",
    "    for (data, target) in bar:\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        loss_func = criterion\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data)\n",
    "        loss = loss_func(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_np)\n",
    "        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n",
    "        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def val_epoch(loader, get_output=False):\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    LOGITS = []\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            logits = model(data)\n",
    "\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "            pred = logits.sigmoid().sum(1).detach().round()\n",
    "            LOGITS.append(logits)\n",
    "            PREDS.append(pred)\n",
    "            TARGETS.append(target.sum(1))\n",
    "\n",
    "            val_loss.append(loss.detach().cpu().numpy())\n",
    "        val_loss = np.mean(val_loss)\n",
    "\n",
    "    LOGITS = torch.cat(LOGITS).cpu().numpy()\n",
    "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()\n",
    "    acc = (PREDS == TARGETS).mean() * 100.\n",
    "    \n",
    "    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n",
    "    qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n",
    "    qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n",
    "    print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n",
    "\n",
    "    if get_output:\n",
    "        return LOGITS\n",
    "    else:\n",
    "        return val_loss, acc, qwk\n",
    "\n",
    "import copy\n",
    "PREDS_1 = []\n",
    "TARGETS_1 = []\n",
    "\n",
    "def test_epoch(model, loader, get_output=False):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    LOGITS = []\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            logits = model(data)\n",
    "\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "            pred = logits.sigmoid().sum(1).detach().round()\n",
    "            LOGITS.append(logits)\n",
    "            PREDS.append(pred)\n",
    "            TARGETS.append(target.sum(1))\n",
    "\n",
    "            test_loss.append(loss.detach().cpu().numpy())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "    PREDS_1 = copy.copy(PREDS)\n",
    "    TARGETS_1 = copy.copy(TARGETS)\n",
    "\n",
    "    LOGITS = torch.cat(LOGITS).cpu().numpy()\n",
    "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()\n",
    "    print(PREDS)\n",
    "    print(TARGETS)\n",
    "    \n",
    "    # PREDS_1 = copy.copy(PREDS)\n",
    "    # TARGETS_1 = copy.copy(TARGETS)\n",
    "    \n",
    "    acc = (PREDS == TARGETS).mean() * 100.\n",
    "    \n",
    "    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n",
    "    qwk_k = cohen_kappa_score(PREDS[df_test['data_provider'] == 'karolinska'], df_test[df_test['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n",
    "    qwk_r = cohen_kappa_score(PREDS[df_test['data_provider'] == 'radboud'], df_test[df_test['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n",
    "    print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n",
    "\n",
    "    if get_output:\n",
    "        return LOGITS\n",
    "    else:\n",
    "        return PREDS_1, TARGETS_1, test_loss, acc, qwk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395dd4d0-d740-4a41-bb7e-363042ba40d1",
   "metadata": {},
   "source": [
    "# Create Dataloader & Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58f99f8c-e5f9-4849-affd-85367908a086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "7571 1893 1052\n"
     ]
    }
   ],
   "source": [
    "train_idx = np.where((df_train['fold'] != fold))[0]\n",
    "valid_idx = np.where((df_train['fold'] == fold))[0]\n",
    "\n",
    "df_this  = df_train.loc[train_idx]\n",
    "df_valid = df_train.loc[valid_idx]\n",
    "df_test = df_test.loc[:]\n",
    "\n",
    "dataset_train = PANDADataset(TRAINING_DATA_FOLDER_PATH, df_this, image_size, n_tiles, transform=transforms_train)\n",
    "dataset_valid = PANDADataset(TRAINING_DATA_FOLDER_PATH, df_valid, image_size, n_tiles, transform=transforms_val)\n",
    "dataset_test = PANDADataset(TESTING_DATA_FOLDER_PATH, df_test, image_size, n_tiles, transform=None)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, sampler=SequentialSampler(dataset_test), num_workers=num_workers)\n",
    "\n",
    "model = enetv2(enet_type, out_dim=out_dim)\n",
    "\n",
    "# # Using trained model from 24th early morning (not that helpful but still)\n",
    "# trained_fold_model_file_path: str = '/teamspace/studios/this_studio/04_24_2024_05_38_13_final_fold0.pth'\n",
    "# # model.load_state_dict(torch.load(trained_fold_model_file_path))\n",
    "# # model.load_state_dict(torch.load(trained_fold_model_file_path, weights_only=True))\n",
    "# fold_weights = torch.load(trained_fold_model_file_path)\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#   print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#   # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#   model = nn.DataParallel(model, device_ids=[0,1,2,3])\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)\n",
    "scheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n",
    "\n",
    "print(len(dataset_train), len(dataset_valid), len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c65ce6-708f-478e-902f-d689cdc82539",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "108b40d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04_28_2024_03_50_50\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt_string = datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "print(dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b1ee0d9-7177-4403-9e2e-de0257696803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qwk_max = 0.\n",
    "# best_file = f'{dt_string}_best_fold{fold}.pth'\n",
    "# for epoch in range(1, n_epochs+1):\n",
    "#     print(time.ctime(), 'Epoch:', epoch)\n",
    "#     scheduler.step(epoch-1)\n",
    "\n",
    "#     train_loss = train_epoch(train_loader, optimizer)\n",
    "#     val_loss, acc, qwk = val_epoch(valid_loader)\n",
    "\n",
    "#     content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, acc: {(acc):.5f}, qwk: {(qwk):.5f}'\n",
    "#     print(content)\n",
    "#     with open(f'log_{dt_string}.txt', 'a') as appender:\n",
    "#         appender.write(content + '\\n')\n",
    "\n",
    "#     if qwk > qwk_max:\n",
    "#         print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(qwk_max, qwk))\n",
    "#         torch.save(model.state_dict(), best_file)\n",
    "#         qwk_max = qwk\n",
    "\n",
    "# torch.save(model.state_dict(), os.path.join(f'{dt_string}_final_fold{fold}.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89053532-9b77-46d8-a99b-cdac83cd58a1",
   "metadata": {},
   "source": [
    "# Run Inference Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bc4c066-aebd-42e4-a187-c0a8aa741a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49635/2349884661.py:74: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for (data, target) in tqdm(loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b080f901a35748dd901dad83880ed7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. ... 3. 3. 3.]\n",
      "[3. 1. 4. ... 4. 3. 1.]\n",
      "qwk 0.014613699135250457 qwk_k 0.0097251619311165 qwk_r 0.022587378357608823\n"
     ]
    }
   ],
   "source": [
    "trained_model_file_path: str = '/teamspace/studios/this_studio/trained_models/effnet_b0_LB_0.86.pth'\n",
    "model.load_state_dict(torch.load(trained_model_file_path, map_location=torch.device('cuda')))\n",
    "\n",
    "preds_1, targets_1, test_loss, acc, qwk = test_epoch(model=model, loader=test_loader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
